<html>
<head>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML">
</script>

<link rel="stylesheet" type="text/css" href="style.css">



<title>Taylor Polynomials and Derivatives</title>
</head>
<body>
  <div class="title">
    <h1 id="titleheading"><a href="index.html" class="title-link">Local-to-Global</a></h1>
  </div>
  <hr id="titlebreak">
  
  <h2 id = "titleheading">Taylor Polynomials and Derivatives</h2>
  <div class="post-content">
  <div class="post-date">5/31/2017</div>
  <h3>Tangent Lines and Derivatives</h3>
  <p>
  Typically, if $f(x)$ is a function, then (if it exists), the derivative of $f(x)$ at $x=a$ is typically defined a
  $$
  f'(a) = \lim_{h\rightarrow 0} \frac{f(a+h)-f(a)}{h}
  $$
    The Tangent Line at $x=a$ is then defined as the polynomial
    $$
    P(x) = f(a) + f'(a)(x-a)
    $$
    This is the linear approximation for $f(x)$ at $x=a$. While the tangent line is typically described as the line that "touches at only one point", this is not true and not the importance of the tangent line. Rather, the tangent line is the line that approximates the function around a given point the best. As it stands now, the notion of "best" is pretty vague. Perhaps we can investigate what it means for a line to approximate a function around a point well, and then use this to define the derivative. Our question is then: Can we define the Tangent Lines at $x=a$ to be the line that best approximates $f(x)$ near $x=a$ and then recover the traditional definition for the derivative?
    </p>
    <p>
    To do this, we need to know what a "best approximating line" even means. Obviously such a line will have to pass through the point $(a,f(a))$ and so will be of the form $L(x)=f(a) + m(x-a)$ for some number $m$. For such a line, we have that
      $$
      \lim_{x\rightarrow a} f(x)-L(x) = 0
      $$
      This means that $L(x)$ approximates $f(x)$ to the 0th order at $x=a$. All this means is that they have the same value at $x=a$. To strengthen this, we should look towards a 1st order approximation of $f(x)$ at $x=a$. We have that $f(x)-L(x)$ goes to zero, and that $x-a$ goes to zero at $x=a$. If we divide them to get $\frac{f(x)-L(x)}{x-a}$, then we don't have to have this go to zero at $x=a$. If it does go to zero, then that implies that $f(x)-L(x)$ goes to zero faster than $x-a$ goes to zero, which implies a faster and better approximation. Towards this end, we make the definition:
    </p>  
    <div class = "thm"><b>Definition:</b> Let $f(x)$ be a function and $T(x)$ a line of the form $T(x)=f(a)+m(x-a)$. We say that $T(x)$ is a <b>Tangent Line</b> of $f(x)$ at $x=a$ if
      $$
      \lim_{x\rightarrow a} \frac{f(x)-T(x)}{x-a} = 0
      $$
    </div>
    <p>
      The main result is that there is at most one tangent line at any point. Furthermore, the slope of this unique tangent line is the derivative of $f(x)$ at $x=a$. Therefore, the above definition of the tangent line is equivalent to the definition of the derivative. Yet is is a bit more conceptually motivated by the need to find good approximations. Let's state a prove this statement:
    </p>
    <div class="thm"><b>Theorem:</b> Let $f(x)$ be a function. There is at most one tangent line at any point for $f(x)$. Furthermore, if it exists, the slope of the tangnet line is given as
      $$
      f'(a) = \lim_{h\rightarrow} \frac{f(a+h)-f(a)}{h}
      $$
    </div>
    <div class="thm"><b>Proof: </b>
      <p>
      Let $O(x)=f(x)-L(x)$, we then obviously have 
    $$
    f(x) = f(a) + m(x-a) + O(x)
    $$
      We call this the "error" of the approximation. For any line $\lim_{x\rightarrow a}O(x)=0$. $L(x)$ is a tangent line if, additionally, $\lim_{x\rightarrow a}\frac{O(x)}{x-a}=0$.
      </p>
    <p>
      So let $L(x)$ be any line passing through $(a,f(x))$. Assume that the limit 
    $$
    \lim_{x\rightarrow a} \frac{O(x)}{x-a} = c
    $$
     also exists and equals $c$. With this assumption, we can write $O(x)=c(x-a)+o(x)$, where $\lim_{x\rightarrow a}o(x)/(x-a)=0$. We can plug this into $f(x)=f(a)+m(x-a) + O(x)$ to get
     $$
     f(x) = f(a) + M(x-a) +o(x)
     $$
     where $M=m+c$. If we set $T(x)=f(a)+M(x-a)$, the it is easy to check that $\lim_{x\rightarrow a} \frac{f(x)-T(x)}{x-a} = 0$. So under the assumption that $\lim_{x\rightarrow a} \frac{O(x)}{x-a}$ exists for some line $L(x)$, means that we can find at least one that satisfies the optimization condition of a tangent line.
      </p>
      <p>
        We will show that there is only a single tangent line by finding a formula for $M$. Taking the equation $f(x)=f(a)+M(x-a)+o(x)$ and solving for $M$ gives
     $$
     M = \frac{f(x)-f(a)}{x-a} - \frac{o(x)}{x-a}
     $$
     Note that the left side does not depend on $x$, so we are free to take the limit of this expression at $x=a$ without changing $M$. Since the limit of the second term on the right is zero, doing this then gives
     $$
     M = \lim_{x\rightarrow a}\frac{f(x)-f(a)}{x-a}
     $$
     Which can be turned into the typical expression for the derivative through the change of variables $h=x-a$. 
     </p>
    </div>
     <p>
     This means that the definintions around all this are not ad hoc. The derivative arises naturally as the slope of the unique line that approximats a function the <i>best</i> around a point.
    </p>
    <h3>Higher Order Derivatives and Taylor Polynomials</h3>
    <p>
      Does a similar thing work for higher order derivatives? This is actually more delicate than it appears. But first, let us define the higher dergree analog to Tangent Lines.
    </p>
    <div class = "thm"><b>Definition: </b> Let $f(x)$ be a function and let $T(x)$ be a polynomial of degree at most $n$. Say that $T(x)$ is a degree $n$ <b>Taylor Polynomial</b> at $x=a$ if 
      $$
      \lim_{x\rightarrow a} \frac{f(x)-T(x)}{(x-a)^n} = 0
      $$
    </div>
    <p>
      So a tangent line is a degree 1 Taylor polynomial. All we have done is increase the degree of any polynomial-type expression going in the tangent line definition. This definition then works to find the degree $n$ polynomial that best approximates our function around a given point. The question is then: Is this unique? and How does this relate to higher order derivatives? Let's address the uniqueness first.
    </p>
    <div class="thm"><b>Theorem: </b>Let $f(x)$ be a function. For every point $x=a$, there is at most one Taylor polynomial of degree $n$ for $f(x)$ at $x=a$. Furthermore, if the Taylor polynomial of degree $n$ exists at $x=a$, so does the Taylor Polynomial of degree $n-1$ at $x=a$. Explicitly, if $T(x)$ is the degree $n$ Taylor polynomial for $f(x)$ at $x=a$ with leading term $Mx^(n)$, then $P(x)=T(x)-Mx^n$ is the degree $n-1$ Taylor polynomial for $f(x)$ at $x=a$ and
      $$
      M = \lim_{x\rightarrow a}\frac{f(x)-P(x)}{(x-a)^n}
      $$
    </div>
    <div class="thm"><b>Proof: </b> This will be done through induction. The base case is the Tangent Line theorem above. So assume that $n>1$ and assume that $P(x)$ is the degree $n-1$ Taylor polynomial at $x=a$. Let $Q(x)=P(x)+m(x-a)^n$ and write $O(x)=f(x)-Q(x)$. Assume that
      $$
      \lim_{x\rightarrow a}\frac{O(x)}{(x-a)^{n}}=c
      $$
      exists and is equal to $c$. We can then write $O(x)=c(x-a)^n +o(x)$, where $\lim_{x\rightarrow a}\frac{o(x)}{(x-a)^n}=0$. Plugging the expression for $O(x)$ into $f(x)=Q(x)+O(x)$ gives
      $$
      f(x) = P(x) + M(x-a)^n + o(x)
      $$
      where $M=m+c$. Setting $T(x)=P(x)+M(x-a)^n$, we find that
      $$
      \lim_{x\rightarrow a}\frac{f(x)-T(x)}{(x-a)^n} = 0
      $$
      Therefore, under the assumption that there is some $m$ so that the above limit exists, we get the existence of a degree $n$ Taylor polynomial. To show that this is unique, we'll find an expression for $M$. Solving $f(x)=P(x)+M(x-a)^n+o(x)$ for $M$ gives
      $$
      M = \frac{f(x)-P(x)}{(x-a)^n} - \frac{o(x)}{(x-a)^n}
      $$
      Since the left side of this does not depend on $x$, we can take the limit of this at $x=a$. Doing this then gives
      $$
      M = \lim_{x\rightarrow a}\frac{f(x)-P(x)}{(x-a)^n}
      $$
      So this polynomial is unique.
    </div>
    <p>
      Note that this proof is nearly identical to our above proof. This is because the degree 0 case is actually the base case, and $P(x)=f(a)$ is the unique degree 0 Taylor polynomial. Repeating the above with $P(x)=f(a)$ and $n=1$ gives us the Tangent Line proof. The only difference is that we don't really get the expression for the $n$th order derivative. This is actually important because you can have a degree $n$ Taylor polynomial without having an $n$th order derivative. The reason for this is that it might be the case that a function has a derivative only at $x=a$, but not at any point around $x=a$. In this case, it does not make sense to talk about the higher order derivatives, but it might make sense to talk about the higher order Taylor polynomials.    </p>
    <p>
      Since the Taylor polynomials can exist without the $n$th order derivatives themselves existing, we can define a kind of generalized derivative in terms of the coefficients of the Taylor polynomials:
    <div class="thm"><b>Definition: </b> Let $f(x)$ be a function and assume it has a degree $n$ Taylor polynomial 
      $$
      T(x)=m_n(x-a)^n + m_{n-1}(x-a)^{n-1}+\cdots+m_1(x-a)+m_0
      $$
      at $x=a$. For $k\leq n$, say that the <b>Generalized $k$th Order Derivative</b> at $x=a$, denoted $f^{[k]}(a)$, is equal to
      $$
      f^{[k]}(a) := m_k k!
      $$
      From the above theorem, this does not depend on the choice of $n$.
    </div>
    <p>
      A main result on the theory of Taylor Series can then be seen as follows: If $f(x)$ is $n$-times differentiable, with $n$th derivative $f^{(n)}(a)$, then we have
      $$
      f^{(n)}(a)=f^{[n]}(a)
      $$
      Of course, the values $f^{[n]}(a)$ can exist without $f^{(n)}(a)$ existing.
    </p>
    <h3>Conclusion</h3>
    <p>
      The advantage of all of this is putting everything into terms of approximation. We define what we want a good linear approximation to be and then show that derivatives are then seen as important because of how they let us approximate functions in this way. Same thing for Taylor polynomials. We discuss what we want by a good polynomial approximation to a function, and see, as a corollary, that higher order derivatives accomplish this. An emphasis on approximation can make Calculus a lot more concrete and conceptually meaningful.
    </p>
    
    
    
    
    
  </div>



</body>
</html>
