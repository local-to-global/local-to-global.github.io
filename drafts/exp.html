<html>
<head>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML">
</script>

<link rel="stylesheet" type="text/css" href="style.css">



<title>The Exponential and Logarithmic Functions</title>
</head>
<body>
  <div class="title">
    <h1 id="titleheading"><a href="index.html" class="title-link">Local-to-Global</a></h1>
  </div>
  <hr id="titlebreak">
  
  <h2 id = "titleheading">The Exponential and Logarithmic Functions</h2>
  <div class="post-content">
  <div class="post-date">11/21/2016</div>
    <p>
    One of the fundmantal constants in math is Euler's number $e$. Though, its importance is not really anything to do with the number itself, rather it is the function $\exp(x)=e^x$ that is important, along with its inverse function $\log(x)$ (where the base is $e$). We'll look at the many definitions of these functions and see how they are all equivalent. Each of these definitions can be used to highlight different important aspects of these functions.
    </p>
    <h3> The Exponential Function</h3>
    <p>Let us first look at the exponential function. We'll explore variouos possible definitions of it and the proof that they are all actually the same function. We'll also discuss the context of each of these and what they say about the function, or $e$, theoretically.
    </p>
    <ol>
    <li>Our first definition is related the one where $e$ first appeared explicitly. In this case, we define
    $$
    \exp(x) := \lim_{N\rightarrow\infty} \left(1+\frac{x}{N}\right)^N
    $$
    The term on the inside of the parentheses goes to zero, whereas the exponent goes to infinity, and these two behaviours balance out for every real value $x$. This is not obviously a function of the form $A^x$, for some $A$, but it will be shown that $\exp(x)=e^x$. An interesting thing about this is that it is valid for all real $x$ but only requires integer exponents. In a way, we can then use this as the definition of negative, rational or real valued exponents through the expression $A^x:=\exp(\log(A)x)$. Historically, this expression pops up when studing compound interest and probability. The famous $A=Pe^{rt}$ formula comes directly from evaluating this limit, and in probability, if you have some event that succeeds with a chance of $1/N$, then $(1-1/N)^N$ are the chances that you fail exactly $N$ times. Hence $\exp(-1)$ is the limit of this as $N$ goes to infinity.
      <br>
    </li>
    <li>
    Next, we define $\exp(x)$ via differential equations. We can interpret differentiation as a linear operator on vector spaces of functions. It can be hard to understand linear operators, but one of the main tools we have is eigenvectors. In the special case of differentiable operators, we are interested in nonzero differentiable functions $f(x)$ that satisfy $f'(x)=cf(x)$ for some constant value $c$, this will make $f(x)$ an eigenvector and means that it interacts very nicely when differentiated. We can go a bit futher. If $f'(x)=cf(x)$, then, by the Chain Rule, this means that $f'(x/c)= f(x/c)$. This suggests from the particular eigenvector that has $c=1$, that we can recover all the others. So we defin $\exp(x)$ to be the unique nonzero differentiable function satistfying $\exp(0)=1$ and $\exp'(x)=\exp(x)$. If $f(x)$ is any other eigenvector with $f(0)=1$ and $f'(x)=cf(x)$ then $f(x)=\exp(cx)$. This means that $\exp(x)$ universally encodes all such functions.
      <br></li>
      <li> We now define the exponential function via its functional properties, which is done through functional equations. As an example of what this means, if $f(x)$ is any continuous function so that $f(x+y)=f(x)+f(y)$, then it must be that $f(x)=cx$ for some constant $c$. We will do the analogous for the exponential function. We first note that if $f(x)$ is a continuous function so that $f(x+y)=f(x)f(y)$, then it follows that $f(x)$ is differentiable. This requires some technical analysis of such functions, but we will take it for granted. So if $f(x)$ is such a function, then we can assume it is differentiable. Define, then $\exp(x)$ to be the unique continuous function so that $\exp(x+y)=\exp(x)\exp(y)$ and $\exp'(0)=1$.
      <br></li>
    <li>
    We can also define the exponential function via infinite series. Explicitly, 
    $$
    \exp(x) := \sum_{n=0}^{\infty} \frac{x^n}{n!}
    $$
    This definition has the advantage of being very flexible. This definition allows us to analytically define the exponential function in many different arithmetic systems. Most notably, for matricies, complex numbers and $p$-adic numbers. The expression for $\exp(-1)$ through this can arise from combinatorics as well, when counting derrangements. 
      </li>
    </ol>
    <h4>Proofs of Equivalence</h4>
    We can now prove the following result about the above three defintions:
    <div class="thm"><b>Theorem: </b> Define the functions $\exp_1(x)$, $\exp_2(x)$, $\exp_3(x)$ and $\exp_4(x)$ as above. Then each of these is defined for all real $x$ and, moreover, we have 
    $$
    \exp_1(x)=\exp_2(x)=\exp_3(x)=\exp_4(x)
    $$
    Let $\exp(x)$ denote this function. Furthermore, if $e=\exp(1)$, then we have $\exp(x)=e^x$ where this exponentiation is traditionally defined. 
    </div>
    <div class="thm"><b>Proof:</b> We will prove $\exp_1(x)=\exp_4(x)$ and $\exp_2(x)=\exp_4(x)$ and finally $\exp_3(x)=\exp_2(x)$. 
    <ol>
      <li>Consider the term $(1+x/N)^N$. We can expand this using the Binomial Theorem as
    $$
    (1+x/N)^N = \sum_{k=0}^N \binom{N}{k} \frac{x^k}{N^k}
    $$
    We find that $\binom{N}{k}\frac{1}{N^k} = \frac{N(N-1)\cdots(N-k+1)}{k!N^k}$. The numerator of this will be of the form 
    $$
    N(N-1)\cdot (N-k+1) = N^k + (\textrm{Lower Order Terms})
    $$
    That is, the numerator is a polynomial of degree $k$ in the variable $N$ with leading term $N^k$. When dividing this through by $N^k$, we find that this is the only term that doesn't have an $N$ in the numerator. Therefore, we have 
    $$
    \binom{N}{k}\frac{1}{k!} = \frac{1}{k!} + \frac{1}{N}s_{N,k}
    $$
    where $s_{N,k}$ is some expressions so that $\lim_{N\rightarrow \infty} s_{N,k} &lt \infty$. We then can write
    $$
    \left(1+\frac{x}{N}\right)^N = \sum_{k=0}^N \frac{x^k}{k!} + \frac{x^k}{N}s_{N,k}
    $$
    The second term goes to zero in the limit $N\rightarrow\infty$ and so we have
    $$
    \lim_{N\rightarrow\infty}\left(1+\frac{x}{N}\right)^N = \sum_{k=0}^{\infty}\frac{x^k}{k!}
    $$
    and we get $\exp_1(x)=\exp_4(x)$. It should be noted that the convergence of the power series is easy to demonstrate for all $x$, and this equality allows us to say that the limit of $(1+x/N)^N$ exists for all $x$ as well.
    <br></li>
    <li>
    Next, we'll show that $\exp_4(x)$ satisfies the initial value problem $f'(x)=f(x)$ with $f(0)=1$ and, since this is a first order linear equation, we must have $\exp_2(x)=\exp_4(x)$. We note that we can differentiate power series term-by-term. Doing this with the power series expression $\exp_4(x)=\sum_{k=0}^{\infty}\frac{x^k}{k!}$, we find that $\exp_4'(x)=\exp_4(x)$. Furthermore, direct computation shows that $\exp_4(0)=1$. Hence $\exp_2(x)=\exp_4(x)$. 
   <br> </li>
      <li>
        Now consider $\exp_3(x)$. This is the differentiable function that satisfies $\exp_3(x+y)=\exp_3(x)\exp_3(y)$ and $\exp_3(0)=1$. We will show that $\exp_3(x)=\exp_2(x)$ by showing that $\exp_3(x)$ satisfies the initial value problem of $\exp_2(x)$. We then explicitly compute the derivative of $\exp_3(x)$:
        $$
        \begin{eqnarray*}
        \exp_3'(x) &=& \lim_{h\rightarrow 0}\frac{\exp_3(x+h)-\exp(x)}{h}\\
                   &=& \lim_{h\rightarrow 0}\frac{\exp_3(x)\exp_3(h)-\exp_3(x)}{h}\\
                   &=& \exp_3(x)\lim_{h\rightarrow 0}\frac{\exp_3(h)-1}{h}\\
                   &=& c\exp_3(x)
        \end{eqnarray*}
        $$
        where $c$ is the limit. Note that we can pullout the $\exp_3(x)$ because the function is nonzero. We must, then, compute this limit. We have $\exp_3(x+y)=\exp_3(x)\exp_3(y)$. Applying this with $y=0$ gives $\exp_3(x)=\exp_3(x)\exp_3(0)$. Since the function is nonzero, we find that $\exp_3(0)=1$. So, using the fact that $\exp_3'(0)=1$, $\exp_3(0)=1$ and $\exp_3'(x)=c\exp_3(x)$, we get that $c=1$. This means that $\exp_3(x)$ satisfies the initial value problem for $\exp_2(x)$ and so $\exp_2(x)=\exp_3(x)$. It should be noted that the differential equation $f'(x)=cf(x)$ can be seen as the infinitesimal version of the functional equation $f(x+y)=f(x)f(y)$.
      </li>
      </ol>
   <p> 
    So these functions are all the same, but it would be good to know that $\exp(x)$ is actually an exponential function. That is, a function of the form $f(x)=A^x$ for some positive $A$. This follows from a famous result of Cauchy that we sketch here. This will use the fact that $\exp(x+y)=\exp(x)\exp(y)$. We will show that if $f(x+y)=f(x)f(y)$ and $f(x)$ is continuous, then $f(x)=A^x$ where $A=f(1)$. We already saw that $f(0)=1$. Induction immediately shows that for positive $N$ then $f(N)=f(1)^N$. It then follows that $1=f(N-N)=f(N)f(-N)$ which implies that $f(-N)=1/f(1)^N$. If $q$ is a rational number, then there is some positive integer $N$ so that $qN$ is an integer. So $f(qN)=f(1)^{qN}$. But this also equals $f(qN)=f(q)^N$, so $f(q)^N=f(1)^{qN}$. There is then a unique positive $N$th root to this, and so we find that $f(q)$ is equal to the unique $N$th root of $f(1)^{qN}$, which is, of course, $f(1)^q$. Finally, if $x$ is real, then we can approximate it by a Cauchy sequence of rational numbers, $q_n$, for each of which $f(1)^{q_n}$ is defined. The limit of this is $f(1)^x$, and by continuity we get $f(x)=f(1)^x$. 
      </p>
    </div>
    <p>
      These are all great definitions, which can be used in different contexts. But each of these is natural in their own context, pointing to the importance of this function.
    </p>
    <h3>The Logarithmic Function</h3>
    <p>
      We now turn to the logarithmic function, particularly the natural logarithm denoted $\log(x)$. This is a function just as natural as the exponential function, and, just as before, we'll look at a bunch of definitions of it in different contexts and prove that they are all the same. 
      <ol>
        <li>
          We first define $\log(x)$ in a way that illuminates the derivative of an exponent more. Define, for $A>0$,
          $$
          \log(A) := \lim_{h\rightarrow 0} \frac{A^h-1}{h}
          $$
          Obviously, with this definition, we find that $\frac{dA^x}{dx}=\log(A)A^x$. Furthermore, we naturally have $\log(e)=1$, where $e=\exp(1)$. 
        </li>
        <li>
          Relatedly, we can define 
          $$
          \log(A) := \left(\frac{dA^x}{dx}\right)/A^x
          $$
          While this is only very slightly different from the previous definition, we can naturally extend this definition to any function. In fact, the "Logarithmic Derivative" for a function $f(x)$ is defined to be $f'(x)/f(x)$. We'll show that this is constant  in $x$ if and only if $f(x)=A^x$ for some positive $A$, so that we can take this as the definition of the logarithm.
        </li>
        <li>
          We can then turn to defining $\log(x)$ via its functional properties.  It should be noted that if a function is continuous and satisifes $f(xy)=f(x)+f(y)$, then it is differentiable. Explicitly, we define it as unique continuous function satisfying $\log(xy)=\log(x)+\log(y)$ so that we also have $\frac{d}{dx}\log(x)\Big|_{x=0} = 1$.
        </li>
        <li>
          We can also define it in terms of its derivative. That is, we define $\log(x)$ to be the unique function so that $\frac{d}{dx}\log(x)=1/x$ and $\frac{d}{dx}\log(x)\Big|_{x=0} = 1$. In this way, the equation $\frac{d}{dx}\log(x)=1/x$ can be seen as an infinitesimal version of the equation $\log(xy)=\log(x)+\log(y)$. 
        </li>
        <li>
          A common definition used in higher level courses is to define it as area under a hyperbola. Explicitly, we have
          $$
          \log(x):= \int_{1}^{x}\frac{dt}{t}
          $$
        </li>
        <li>
          Finally, we define it via power series. For $0&lt x &lt 2$ we first define
                                                              $$
                                                              L(x):= -\sum_{n=1}^{\infty}\frac{(1-x)^n}{n}
                                                              $$
         But this is only value for $0&lt x&lt 2$. If $x>2$, note that there is some smallest integer $\ell_x$ so that $1&lt x^{1/\ell_x} &lt 2$. We then define
          $$
          \log(x) := \ell_x\cdot L(x^{1/\ell_x}) 
          $$
        </li>
    </ol>
          
    <h4>Proofs of Equivalence</h4>
    <p>
      Just as before, we will now prove that each of these definitions are equivalent and, furthermore, they define an actual logarithm. That is, they satisfy $e^{\log(x)}=\log(e^x)=x$.
    </p>
    <div class="thm"><b>Theorem: </b>Let $\log_{(i)}(x)$, for $i=1,...,6$ be the functions defined above. The parenthese are to distinguish them from log-base-$i$. Then we have
      $$
      \log_{(1)}(x)=\log_{(2)}(x)=\log_{(3)}(x)=\log_{(4)}(x)=\log_{(5)}(x)=\log_{(6)}(x)
      $$
      Call this single function $\log(x)$. This is defined for all $x>0$ and is the logarithm-base-$e$:
      $$
      \begin{eqnarray*}
      e^{\log(x)}&=&x\\
      \log(e^y)&=&y
      \end{eqnarray*}
      $$
      for all $x>0$ and all real $y$.
    </div>
    <div class="thm"><b>Proof: </b> We will show this by proving
      $$
      \begin{eqnarray*}
      \log_{(1)}(x) &=& \log_{(2)}(x)\\
      \log_{(1)}(x) &=& \log_{(3)}(x)\\
      \log_{(3)}(x) &=& \log_{(4)}(x)\\
      \log_{(5)}(x) &=& \log_{(4)}(x)\\
      \log_{(6)}(x) &=& \log_{(4)}(x)
      \end{eqnarray*}
      $$
      <ol>
        <li>
          Showing $\log_{(1)}(x)=\log_{(2)}(x)$ follows directly from previous computations with the exponent. Particularly the equation $\frac{dA^x}{dx}=A^x\lim_{h\rightarrow 0}\frac{A^h - 1}{h}$, which we know to exist from the differentiablility of the exponent.
        </li>
        <li>
          We show that $\log_{(1)}(x)=\log_{(3)}(x)$, by showing that $\log_{(1)}(x)$ satisfies $\log_{(1)}(xy)=\log_{(1)}(x)+\log_{(1)}(y)$ and that the derivative at $x=1$ is one. For this, we write $x=1+a$ and $y=1+b$. Then $(xy)^h = (1+a+b+ab)^h$. We can expand this using a Generalized Multinomial Theorem as:
          $$
          (1+a+b+ab)^h = 
          $$

     

</body>
</html>
